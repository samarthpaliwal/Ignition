# Ignition ğŸ”¥  
_A visual AI debugging tool for open-source LLMs_

---

## ğŸ“Œ About  
**Ignition** is a first-of-its-kind debugging and visualization tool for AI.  
It lets you **trace, visualize, and debug** every step of an AIâ€™s reasoning â€” turning black-box models into transparent, controllable systems.  

Built with **PySide6 + llama.cpp + Ollama**, it supports both **local GGUF models** and **Ollama-managed models**, with side-by-side comparison.  

---

## ğŸš€ Features
- âš¡ **Visual Graphs** â€” See every reasoning step as nodes and edges.  
- ğŸ“ **Editable Notes** â€” Edit intermediate steps and re-run downstream.  
- ğŸ” **Why Heatmap** â€” Highlights input words most relevant to the final answer.  
- ğŸ“Š **A/B Benchmark** â€” Compare two models on latency, tokens/sec, and output similarity.  
- ğŸ›¡ï¸ **Guardrails Slider** â€” Control how cautious the model should be.  
- ğŸ”„ **Replay Mode** â€” Watch the AI regenerate its final output token by token.  
- ğŸ’¾ **Save/Load Sessions** â€” Persist and reload your debugging workflow.  

---

## âš™ï¸ Requirements
- Python 3.10+  
- macOS, Linux, or Windows  
- [Ollama](https://ollama.ai) (optional, for streaming models)  

Install dependencies:  
```bash
pip install -r requirements.txt
